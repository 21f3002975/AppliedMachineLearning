{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8625b4c2-6747-44eb-b3a6-43089e7c9b09",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue;\">Notebook Contents</span>\n",
    "\n",
    "### 1. Set up\n",
    "  1. **Loading packages**\n",
    "  2. **Connecting with GPUs**\n",
    "### 2. Data Preparation\n",
    "  1. **Loading data**\n",
    "  2. **Data cleaning**\n",
    "  3. **Creating DataLoaders**\n",
    "### 3. Transfer learning using BERT pre-trained model\n",
    "  1. **Loading the model**\n",
    "  2. **Model finetuning  and training**\n",
    "### 4. Model evaluation\n",
    "  1. **Model evaluation on test data**\n",
    "  \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3b914-7738-44e7-8fdb-86fad06780bc",
   "metadata": {},
   "source": [
    "## 1. Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146eb243-6046-4d05-84ae-6a2357b10cac",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf53205-886f-4500-99c9-acba180b0998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vasu/AjrVasu/Coding/iit/degree/AppliedMachineLearning/envaml/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# utilities\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "#numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# pytorch packages\n",
    "import torch\n",
    "from torch import tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.optim as optim\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# for reproducability\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8561cf7a-fafb-4ca6-9357-afdaad1a5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67527acd-7263-40a5-b185-a094e5df8d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfeb844-1bea-450a-b0ef-769a14dbe60a",
   "metadata": {},
   "source": [
    "### Connecting to GPU/MPS\n",
    "\n",
    "<div style=\"color:red; font-size:16px; background-color:yellow;\">RUN THIS BELOW BLOCK ONLY ON MACBOOK FOR A LOCAL INSTANCE</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c295df47-f96f-47fa-aef1-7951e1b50272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "Using GPU: Metal Performance Shaders (MPS)\n",
      "Tensor: tensor([1., 2., 3.], device='mps:0'), Device: mps:0\n"
     ]
    }
   ],
   "source": [
    "# Run locally if Macbook has a GPU\n",
    "# Is MPS even available? macOS 12.3+\n",
    "\n",
    "print(torch.backends.mps.is_available())\n",
    "\n",
    "# Was the current version of PyTorch built with MPS activated?\n",
    "print(torch.backends.mps.is_built())\n",
    "\n",
    "dtype = torch.float\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using GPU: Metal Performance Shaders (MPS)\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Tensor creation\n",
    "x = tensor([1.0, 2.0, 3.0], device=device, dtype=dtype)\n",
    "print(f\"Tensor: {x}, Device: {x.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ebca0-ec6f-474a-adb1-b30b63777fa7",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e4593-be87-4da4-a6b4-58b6e74d42a2",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "352e55e9-6c06-4e9e-a69c-642d078ed92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data.zip\n",
      "  inflating: data/test.csv           \n",
      "  inflating: data/testdata.manual.2009.06.14.csv  \n",
      "  inflating: data/train.csv          \n",
      "  inflating: data/training.1600000.processed.noemoticon.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip data.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d39ff48-5f5b-400a-b8d0-22c33d2c2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./data/train.csv\", encoding=\"latin1\")\n",
    "df_test = pd.read_csv(\"./data/test.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd318b7-a589-4488-968a-b207b8d07ea7",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57447ce0-8730-4ea9-b70f-3b267ec738d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df_train, df_test):\n",
    "    # Define sentiment to label mapping\n",
    "    labels = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "    \n",
    "    # Extract relevant columns\n",
    "    train = pd.DataFrame(df_train[['text', 'sentiment']])\n",
    "    test = pd.DataFrame(df_test[['text', 'sentiment']])\n",
    "    \n",
    "    # Print initial shapes\n",
    "    print(\"Initial data size:\")\n",
    "    print(\"Train:\", train.shape)\n",
    "    print(\"Test :\", test.shape)\n",
    "    \n",
    "    # Check and print rows with NaNs\n",
    "    print(\"\\nRows with NaN in train:\")\n",
    "    print(train[train.isna().any(axis=1)])\n",
    "    \n",
    "    print(\"\\nRows with NaN in test:\")\n",
    "    print(test[test.isna().any(axis=1)])\n",
    "    \n",
    "    # Drop rows with NaN in either 'text' or 'sentiment'\n",
    "    train.dropna(subset=['text', 'sentiment'], inplace=True)\n",
    "    test.dropna(subset=['text', 'sentiment'], inplace=True)\n",
    "    \n",
    "    # Print shapes after dropping\n",
    "    print(\"\\nData size after dropping NaNs:\")\n",
    "    print(\"Train:\", train.shape)\n",
    "    print(\"Test :\", test.shape)\n",
    "    \n",
    "    # Map sentiment labels\n",
    "    train['label'] = train['sentiment'].map(labels).astype('Int64')\n",
    "    test['label'] = test['sentiment'].map(labels).astype('Int64')\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "399261f7-4171-4968-9fe3-18af916aee32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data size:\n",
      "Train: (27481, 2)\n",
      "Test : (4815, 2)\n",
      "\n",
      "Rows with NaN in train:\n",
      "    text sentiment\n",
      "314  NaN   neutral\n",
      "\n",
      "Rows with NaN in test:\n",
      "     text sentiment\n",
      "3534  NaN       NaN\n",
      "3535  NaN       NaN\n",
      "3536  NaN       NaN\n",
      "3537  NaN       NaN\n",
      "3538  NaN       NaN\n",
      "...   ...       ...\n",
      "4810  NaN       NaN\n",
      "4811  NaN       NaN\n",
      "4812  NaN       NaN\n",
      "4813  NaN       NaN\n",
      "4814  NaN       NaN\n",
      "\n",
      "[1281 rows x 2 columns]\n",
      "\n",
      "Data size after dropping NaNs:\n",
      "Train: (27480, 2)\n",
      "Test : (3534, 2)\n"
     ]
    }
   ],
   "source": [
    "train_clean, test_clean = clean_data(df_train, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a8d75c-44d0-4b33-921b-65f9c8657772",
   "metadata": {},
   "source": [
    "### Creating DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a13e044-1eb5-46d5-ac73-b90672457788",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = list(texts)   # Ensures compatibility even if passed as Series\n",
    "        self.labels = list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65d98f8c-c237-4611-a11b-cecc2d20392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL_NAME = \"bert-base-uncased\"  # Pre-trained model to use\n",
    "MAX_LEN = 128  # Maximum sequence length\n",
    "BATCH_SIZE = 16  # Batch size for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4de81033-7cff-4cc2-8113-7e390004a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(train_data, test_data, model_name=MODEL_NAME, max_len=MAX_LEN, batch_size=BATCH_SIZE):\n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Convert DataFrame columns to lists\n",
    "    train_texts = train_data['text'].tolist()\n",
    "    train_labels = train_data['label'].tolist()\n",
    "    test_texts = test_data['text'].tolist()\n",
    "    test_labels = test_data['label'].tolist()\n",
    "\n",
    "    # Create Dataset instances\n",
    "    train_dataset = SentimentDataset(train_texts, train_labels, tokenizer, max_length=max_len)\n",
    "    test_dataset = SentimentDataset(test_texts, test_labels, tokenizer, max_length=max_len)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39fd7ded-ee96-4899-8936-5ee65309a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_data_loaders(train_clean, test_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d36b2-c4ca-4674-bcf8-95e6f98deed0",
   "metadata": {},
   "source": [
    "## 3. Transfer learning using BERT pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e8633-6482-4c12-abed-cdbaa0acfdb0",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5f6f6d6-ab72-49ae-924d-fecc89cac172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3  # 3 sentiment classes: negative, neutral, positive\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2b0b44-78e2-4328-bf9f-3f04ba3dc998",
   "metadata": {},
   "source": [
    "### Setting up hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c054d5a-96ef-4844-b224-e9c7ef4e9e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 2  # Number of training epochs\n",
    "LEARNING_RATE = 2e-5  # Learning rate for fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076cd6dc-8ddb-45e4-9c78-ec201491a57a",
   "metadata": {},
   "source": [
    "### Setting up the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "119cc041-1c28-4c92-b9b4-91c3b6161a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5451a-f097-4cdf-b99d-e815743d7175",
   "metadata": {},
   "source": [
    "### Model training and fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d07f23e-ad24-45ba-a268-81c96c0b5fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, device, epochs):   \n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "        total_loss = 0.0\n",
    "        total_batches = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_batches += 1\n",
    "\n",
    "            # Collect predictions and labels\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            if (batch_idx + 1) % 500 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item():.6f}\")\n",
    "\n",
    "        avg_loss = total_loss / total_batches\n",
    "        print()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Average Training Loss: {avg_loss:.6f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    \n",
    "    # Overall Accuracy\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Overall Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "    # Classification Report\n",
    "    label_names = [\"negative\", \"neutral\", \"positive\"]\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=label_names))\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in: {total_time:.2f} seconds\")\n",
    "\n",
    "    return model\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "88638ddc-1f74-426b-83cf-28cba4dfa951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Batch 500/1718, Loss: 0.091535\n",
      "Epoch 1/2, Batch 1000/1718, Loss: 0.282913\n",
      "Epoch 1/2, Batch 1500/1718, Loss: 0.389963\n",
      "\n",
      "Epoch 1/2, Average Training Loss: 0.267246\n",
      "--------------------------------------------------\n",
      "Epoch 2/2, Batch 500/1718, Loss: 0.139332\n",
      "Epoch 2/2, Batch 1000/1718, Loss: 0.037191\n",
      "Epoch 2/2, Batch 1500/1718, Loss: 0.180195\n",
      "\n",
      "Epoch 2/2, Average Training Loss: 0.157689\n",
      "--------------------------------------------------\n",
      "Overall Accuracy: 94.49%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.95      0.95      7781\n",
      "     neutral       0.93      0.94      0.94     11117\n",
      "    positive       0.95      0.95      0.95      8582\n",
      "\n",
      "    accuracy                           0.94     27480\n",
      "   macro avg       0.95      0.95      0.95     27480\n",
      "weighted avg       0.94      0.94      0.94     27480\n",
      "\n",
      "\n",
      "Training completed in: 421.34 seconds\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, train_loader, optimizer, device, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f86ea5-6fd9-47a2-9183-fb13e529634c",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d373724a-8319-4dbc-854c-2fdf92f32c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    start_time = time.time()\n",
    "\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, predicted = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "            true_labels.extend(labels.tolist())\n",
    "            predictions.extend(predicted.cpu().tolist())\n",
    "\n",
    "    # Overall Accuracy\n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Overall Evaluation Accuracy: {acc * 100:.2f}%\")\n",
    "\n",
    "    # Classification report\n",
    "    label_names = [\"negative\", \"neutral\", \"positive\"]\n",
    "    print(\"\\n Classification Report on test data:\")\n",
    "    print(classification_report(true_labels, predictions, target_names=label_names))\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89264306-d12d-42ca-a4dd-fbb0f2440782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Evaluation Accuracy: 78.32%\n",
      "\n",
      " Classification Report on test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.80      0.78      1001\n",
      "     neutral       0.75      0.74      0.75      1430\n",
      "    positive       0.85      0.82      0.83      1103\n",
      "\n",
      "    accuracy                           0.78      3534\n",
      "   macro avg       0.79      0.79      0.79      3534\n",
      "weighted avg       0.78      0.78      0.78      3534\n",
      "\n",
      "\n",
      "Training completed in: 14.90 seconds\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(trained_model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
